{"config":{"lang":["nl"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welkom bij Machine Learning","text":"<p>Hier vindt u onder andere de stof (per week) en de opgaven (per blok, of \"deel\", van twee weken).</p>"},{"location":"index.html#inleiding","title":"Inleiding","text":"<p>Machine learning is het onderdeel van de informatica dat zich bezighoudt met het analyseren van grote hoeveelheden data en op basis daarvan structuren herkennen of voorspellingen doen. Hoewel de basis voor dit vakgebied al in de jaren zestig van de vorige eeuw is gelegd (bijvoorbeeld door het baanbrekende werk van Frank Rosenblatt, is het pas de voorbije twee decennia echt tot grote bloei gekomen. Dit heeft vooral te maken met de enorme hoeveelheid data die heden ten dage beschikbaar wordt gesteld (een fenomeen bekend onder de term information explosion in combinatie met de grote en goedkope computationele kracht van hedendaagse computers en data-centra.</p>"},{"location":"index.html#opgaven","title":"Opgaven","text":"<p>Op deze pagina's zijn de weekopgaven van dit onderdeel te vinden. Deze opgaven worden gemaakt in duo's. Tijdens het eerste practicum wordt klassikaal een begin gemaakt met de opgaven: er wordt uitgelegd hoe te werken met numpy en hoe je lineaire algebra gebruikt in het domein van ML. Ook worden hier de weekopgaven verder toegelicht.</p> <p>Telkens tijdens het tweede practicum van elke tweede week worden afspraken gemaakt met individuele duo's om het werk tot dan toe te bespreken, vragen te beantwoorden en opmerkingen te plaatsen. Tijdens deze gesprekken wordt ook het begrip van de materie getoetst.</p> <p>Er zijn vier sets opgaven die uiteindelijk in de voorlaatste week van periode 4.1 moeten zijn afgerond (je bent dus vrij om \u00e9\u00e9n en ander te plannen, zo lang je maar aan deze eis voldoet). Eventueel reparatiewerk wordt tijdens de gesprekken besproken. Mocht dat niet voor de deadline zijn afgerond, dan is er een uitloopmogelijkheid in de laatste week van de periode; dat geldt dan wel als een herkansing: als je hiervan gebruik maakt, kun je voor dit onderdeel maximaal een 6 halen. Voor het overige zijn de cijfers ONV, 6, 8 of 10.</p>"},{"location":"index.html#opstarten","title":"Opstarten","text":"<p>De opgaven voor elke week gaan uit van een zipje met startcode. Het geheel gaat uit van een aantal dependencies. Deze dependencies hebben we voor het gemak in een <code>requirements.txt</code> gezet. Je kunt het beste een virtuele omgeving aanmaken en hierin met pip in \u00e9\u00e9n keer alle dependencies installeren. Hier een voorbeeld voor MacOS:</p> <pre><code>baba@aurelia ~ % virtualenv ml\ncreated virtual environment CPython3.8.7.final.0-64 in 820ms\nbaba@aurelia ~ % cd ml \nbaba@aurelia ml % cp ~/Downloads/requirements.txt .\nbaba@aurelia ml % source bin/activate\n(ml) baba@aurelia ml % python -m pip install -r requirements.txt \n...\n(ml) baba@aurelia ml % \n</code></pre>"},{"location":"index.html#stof-en-opgaven-per-week","title":"Stof en opgaven per week","text":""},{"location":"index.html#deel-1","title":"Deel 1","text":"<ul> <li>Week 1</li> <li>Week 2</li> <li>Inlevermoment</li> </ul>"},{"location":"index.html#deel-2","title":"Deel 2","text":"<ul> <li>Week 3</li> <li>Week 4</li> <li>Inlevermoment</li> </ul>"},{"location":"index.html#deel-3","title":"Deel 3","text":"<ul> <li>Week 5</li> <li>Week 6</li> <li>Inlevermoment</li> </ul>"},{"location":"index.html#deel-4","title":"Deel 4","text":"<ul> <li>Week 7</li> <li>Week 8</li> <li>Inlevermoment</li> </ul>"},{"location":"week1/index.html","title":"Week 1: Tools en technieken","text":"<ul> <li>Jupyter Noteboook</li> <li>hele cyclus doorlopen: data cleaning and preparation</li> <li>numpy, pandas, sklearn</li> </ul>"},{"location":"week2/index.html","title":"Week 2: Lineaire regressie","text":"<ul> <li>kostenfunctie en gradient descent</li> <li>lineaire regressie</li> </ul>"},{"location":"week2/inleveren.html","title":"Inleveren deel 1","text":"<ul> <li>ScikitLearn en California Housing (prep. en lin. regressie): https://hanze-hbo-ict.github.io/OpgavenML/files/intro%20notebook%20en%20sklearn.html</li> <li>Oude set week 1: https://hanze-hbo-ict.github.io/OpgavenML/week1.html</li> </ul>"},{"location":"week3/index.html","title":"Week 3: Logistische regressie en Neurale netwerken (1)","text":"<ul> <li>logistische regressie</li> <li>neurale netwerken 1</li> </ul>"},{"location":"week4/index.html","title":"Week 4: Neurale netwerken (2)","text":"<ul> <li>neurale netwerken 2</li> </ul>"},{"location":"week4/inleveren.html","title":"Inleveren deel 2","text":"<ul> <li>Losse opgave log. regressie: nog maken</li> <li>Oude set week 2: https://hanze-hbo-ict.github.io/OpgavenML/week2.html</li> </ul>"},{"location":"week5/index.html","title":"Week 5: Model-evaluatie","text":"<ul> <li>confusion matrix</li> <li>ROC / AUC</li> </ul>"},{"location":"week6/index.html","title":"Week 6: Andere modellen","text":"<ul> <li>SVC</li> <li>k-means en DBSCAN</li> <li>beslisbomen</li> <li>Random Forest</li> </ul>"},{"location":"week6/inleveren.html","title":"Inleveren deel 3","text":"<ul> <li>Oude set week 3: https://hanze-hbo-ict.github.io/OpgavenML/week3.html (minus opgave 3)</li> <li>Oude set week 4: https://hanze-hbo-ict.github.io/OpgavenML/files/Opdracht%20model-evaluatie.html</li> <li>Opgaven SVC en DBSCAN: heeft Bart, nog vergaren</li> </ul>"},{"location":"week7/index.html","title":"Week 7: Hyperparameter tuning","text":"<ul> <li>hyperparameter tuning</li> <li>GridSearchCV</li> <li>RandomizedSearchCV</li> <li>...and their halving counterparts</li> </ul>"},{"location":"week8/index.html","title":"Week 8: Geavanceerde onderwerpen","text":"<ul> <li>large language models</li> <li>dimensionaliteitsreductie en PCA</li> <li>ensemble learning</li> <li>informatie-entropie</li> </ul>"},{"location":"week8/inleveren.html","title":"Inleveren deel 4","text":"<ul> <li>Opgave over hyperparam tuning: nog ontwikkelen</li> <li>Vrije opgave over leuke dingen: nog ontwikkelen</li> </ul>"}]}